{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e643b78-ccbf-4332-9239-cfb8bde6e2d8",
   "metadata": {},
   "source": [
    "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628548b9-4baa-41e5-a4bc-7ce06b47989d",
   "metadata": {},
   "source": [
    "Web scraping is a technique that extracts large amounts of data from websites. It's used by people and businesses to generate insights and make decisions. \n",
    "\n",
    "Here are some areas where web scraping is used:      \n",
    "Real estate     \n",
    "Web scraping can be used to retrieve data about properties, sale prices, rental income, and more. This data can be used for property value appraisals, rental yield estimates, and real estate market trends analysis.       \n",
    "Marketing      \n",
    "Web scraping can be used to generate leads for marketing. It can also be used for price comparison and competition monitoring.    \n",
    "Data analysis      \n",
    "Web scraping can be used for data analysis, academic research, and training and testing data for machine learning projects.    \n",
    "Other uses of web scraping include:       \n",
    "Price monitoring     \n",
    "Financial data aggregation      \n",
    "Monitoring consumer sentiment     \n",
    "News tracking    \n",
    "Lead generation    \n",
    "Market research    \n",
    "Web indexing              \n",
    "Web mining and data mining      \n",
    "Product review scraping    \n",
    "Weather data monitoring    \n",
    "Website change detection     \n",
    "Web scraping can provide businesses with a competitive edge. By monitoring rivals' activities, companies can adjust their strategies and identify gaps in the market. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527a2e8-3e37-45ed-968a-94e04f7cd50a",
   "metadata": {},
   "source": [
    "# Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad370d-d6cb-4b4e-9fc8-cc48377eacaa",
   "metadata": {},
   "source": [
    "there are many ways to perform web scraping to get data from websites. These include using online services, special APIs, or even creating code for web scraping from scratch. Many large websites, such as Google, Twitter, Facebook, StackOverflow, etc. have APIs that allow you to access your data in a structured format.   \n",
    "Techniques     \n",
    "Human copy-and-paste. The simplest form of web scraping is manually copying and pasting data from a web page into a text file or spreadsheet.     \n",
    "Text pattern matching.   \n",
    "HTTP programming.   \n",
    "HTML parsing.    \n",
    "DOM parsing.    \n",
    "Vertical aggregation.    \n",
    "Semantic annotation recognizing.    \n",
    "Computer vision web-page analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44a616-6b95-47a7-9cd9-22805c111d7d",
   "metadata": {},
   "source": [
    "# Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c9e8c5-2bbc-47d2-9582-3daf76820711",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library that parses HTML and XML documents. It creates a parse tree for parsed web pages that can be used to extract, navigate, search, and modify data from HTML.     \n",
    "Beautiful Soup is mainly used for web scraping. It provides a set of well defined methods for extracting information contained within HTML tags in a website.      \n",
    "Here are some steps for building a web scraping pipeline using BeautifulSoup:      \n",
    "Identify your goal and explore the website of interest     \n",
    "Inspect web page's HTML     \n",
    "Install and import libraries    \n",
    "Retrieve website and parse HTML    \n",
    "Extract, clean, and store data   \n",
    "Save File   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eca030-13d5-4aa7-a4f7-b52715dbea3b",
   "metadata": {},
   "source": [
    "# Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b468df-bd7d-4074-9fc3-5404158a73a6",
   "metadata": {},
   "source": [
    "Flask is a lightweight framework for building websites. It's used for developing web applications using Python.      \n",
    "Here are some reasons why Flask is used in web development projects:      \n",
    "Simple interface     \n",
    "Flask provides a consistent interface for incoming HTTP request data. This makes it easy to build secure and robust web applications.    \n",
    "Built-in development server     \n",
    "Flask provides a built-in development server and a fast debugger.     \n",
    "Easy setup     \n",
    "Flask is easy to set up and allows developers to build web applications according to their own rules.     \n",
    "Accessible for new developers      \n",
    "Flask is a more accessible framework for new developers. It's possible to build a web application quickly using only a single Python file.     \n",
    "In web scraping, Flask can be used to parse collected data and display it as HTML in a new HTML file.      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cea1de-73e3-4bd1-8ace-f35f8a625e19",
   "metadata": {},
   "source": [
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224132f-4d21-4cdc-b41f-e82e207be3e7",
   "metadata": {},
   "source": [
    "Here are the AWS services used in this project:      \n",
    "Amazon Simple Storage Service (S3): S3 is a cloud storage service that provides secure, durable, highly available, and cost-effective object storage. It is used to store and retrieve any type of data, from anywhere on the web. In this project, S3 is used to store the training data for the machine learning model.       \n",
    "\n",
    "Amazon Elastic Compute Cloud (EC2): EC2 is a web service that provides secure, resizable compute capacity in the cloud. It allows you to launch virtual machines (VMs) with a variety of operating systems and configurations. In this project, EC2 is used to host the machine learning model and the web application that serves the model.      \n",
    "Amazon Relational Database Service (RDS): RDS is a web service that makes it easy to set up, operate, and scale a relational database in the cloud. It supports a variety of database engines, including MySQL, PostgreSQL, Oracle, and SQL Server. In this project, RDS is used to store the data that the machine learning model is trained on.     \n",
    "Amazon Lambda: Lambda is a serverless compute service that allows you to run code without provisioning or managing servers. It can be used to implement a variety of backend services, such as processing data, generating responses, and automating tasks. In this project, Lambda is used to serve the machine learning model and to generate responses to user queries.      \n",
    "Amazon Cognito: Cognito is a user identity service that enables you to manage users and authentication for web and mobile applications. It provides secure access control, user registration, and social login. In this project, Cognito is used to authenticate users and authorize access to the machine learning model.     \n",
    "Amazon CloudFront: CloudFront is a content delivery network (CDN) that provides fast, secure, and reliable content delivery to users worldwide. It can be used to deliver static and dynamic content, such as web pages, images, videos, and APIs. In this project, CloudFront is used to deliver the machine learning model and the web application to users worldwide.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
